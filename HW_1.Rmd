---
title: "Approximation of Standard Normal Distribution by the Monte Carto Methods"
author:   
  - Zheng Fang^[<zheng.fang@uconn.edu>; Master student at
    Department of Mathmetics, University of Connecticut.]
  - Qian Zhao^[<qian.4.zhao@uconn.edu>; Master student at
    Department of Mathmetics, University of Connecticut.] 
date: "2018/1/28"
output: pdf_document
abstract: |
    This article is mainly desired to using the Monte Carlo methods to approximate the distribution of standard normal distribution, which is also know as N(0, 1)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction {#sec:intro}
Monte Carlo methods (or Monte Carlo experiments) are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. Their essential idea is using randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches.

In principle, Monte Carlo methods can be used to solve any problem having a probabilistic interpretation. By the law of large numbers, integrals described by the expected value of some random variable can be approximated by taking the empirical mean (a.k.a. the sample mean) of independent samples of the variable. When the probability distribution of the variable is parametrized, mathematicians often use a Markov chain Monte Carlo (MCMC) sampler. The central idea is to design a judicious Markov chain model with a prescribed stationary probability distribution. That is, in the limit, the samples being generated by the MCMC method will be samples from the desired (target) distribution. By the ergodic theorem, the stationary distribution is approximated by the empirical measures of the random states of the MCMC sampler.



# Math Equations
CDF of standard normal distribution:
\begin{align}
    \Phi(t) = \int^t_{-\infty} \frac{1}{\sqrt{2\pi}}e^{-y^2/2}dy
\end{align}
Approximated CDF by Monte Carlo methods:
\begin{align}
    \hat{\Phi(t)} = \frac{1}{n}\sum_1^nI(X_i\leq t)
\end{align}



# Data Generated by Computer
By using function rnorm, we generate a N dimantion vetor X of ramdom numbers that according to the standard normal distribution, where N = {10^2, 10^3, 10^4}. below is one example of vector X when N = 100, and each experiment should repeat 100 times.
```{r X}
set.seed(1)
X <- rnorm(100, mean = 0, sd = 1)
knitr::kable(X)
```



# Figures

```{r, echo=FALSE}
t <- c(0.0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72)
y <- matrix(data = "numeric", nrow = 100, ncol = 9)
X <- rnorm(100, mean = 0, sd = 1)
for (i in 1:9){
  y[1,i] <- 1/100 * sum( I(X <= t[i]) )}
plot(t, y[1, ], ylab = "y", main = "N=100", pch = 20)
for (j in 2:100){
X <- rnorm(100, mean = 0, sd = 1)
for (i in 1:9){
y[j,i] <- 1/100 * sum( I(X <= t[i]) )}
points(t, y[j, ], pch = 20)}
```

```{r}
t <- c(0.0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72)
y_2 <- matrix(data = "numeric", nrow = 1000, ncol = 9)
X_2 <- rnorm(1000, mean = 0, sd = 1)
for (i in 1:9){
  y_2[1,i] <- 1/1000 * sum( I(X_2 <= t[i]) )}
plot(t, y_2[1, ], ylab = "y_2", main = "N=1000", pch = 20)
for (j in 2:1000){
  X_2 <- rnorm(1000, mean = 0, sd = 1)
  for (i in 1:9){
    y_2[j,i] <- 1/1000 * sum( I(X_2 <= t[i]) )}
  points(t, y_2[j, ], pch = 20)}
```

```{r}
t <- c(0.0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72)
y_3 <- matrix(data = "numeric", nrow = 10000, ncol = 9)
X_3 <- rnorm(10000, mean = 0, sd = 1)
for (i in 1:9){
  y_3[1,i] <- 1/10000 * sum( I(X_3 <= t[i]) )}
plot(t, y_3[1, ], ylab = "y_3", main = "N=10000", pch = 20)
for (j in 2:10000){
  X_3 <- rnorm(10000, mean = 0, sd = 1)
  for (i in 1:9){
    y_3[j,i] <- 1/10000 * sum( I(X_3 <= t[i]) )}
  points(t, y_3[j, ], pch = 20)}
```



# Conclusion
By the incresing of the N, the results of the Monte Carlo methods is closer to the standard normal distribution.